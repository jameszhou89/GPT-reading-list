# GPT-reading-list

目标问题
chatGPT所带来的影响力？如何理解是所谓的iphone时刻？
chatgpt跟传统的NLP技术相比，进步的地方是什么？
chatGPT的迭代史
chatGPT的核心技术
chatgpt所带来的场景重构有哪些？产品的机会有哪些？

资料筛选逻辑
第一手资料最重要；
以技术理解为主线；


GPT资料列表
Core
Paper
2017 Attention Is All You Need - 这篇论文介绍了原始的 Transformer 的结构，是 Transformer 系列的基础。
GPT1~GPT4 Openai
2018 Improving language understanding by generative pre-training - 这篇论文介绍了另一个流行的预训练模型，也就是被后人所熟知的 GPT-1。
2019 Language models are unsupervised multitask learners - 这篇论文引入了 GPT-2。
2020 Language Models are Few-Shot Learners - 这篇论文引入了 GPT-3。
2022 Training lanquage models to follow instructions with human feedback - 这篇论文提出了一种 RLHF 的方式
2023 GPT-4  technical report
2022 Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
Sparks of Artificial General Intelligence: Early experiments with GPT-4
Toolformer: Language Models Can Teach Themselves to Use Tools
Talks
openai CEO
Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI | Lex Fridman Podcast
openai CTO
Ilya Sutskever (OpenAI Chief Scientist) - Building AGI, Alignment, Spies, Microsoft, & Enlightenment
GPT-4创造者：第二次改变AI浪潮的方向
黄仁勋与OpenAI首席科学家Ilya Sutskever的炉边谈话 4K 中文字幕

Circle1
Course
李宏毅【機器學習 2023】(生成式 AI)
RLChina 2023 ChatGPT 和大模型春季课程

Talks
What is ChatGPT doing...and why does it work?
GPT-4论文精读
 GPT，GPT-2，GPT-3 论文精读

blog
理解大语言模型——10篇论文的简明清单
ChatGPT的各项超能力从哪儿来？万字拆解追溯技术路线图来了！
LLM大语言模型
通向AGI之路：大型语言模型（LLM）技术精要
压缩即泛化，泛化即智能
Transformer
了解 Transformers 是如何“思考”的
为什么现在的大语言模型（LLM）都是Decoder-only的架构？
Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)
How Transformers Work
RLHF
ChatGPT 背后的“功臣”——RLHF 技术详解 
ChatGPT (可能)是怎麼煉成的 - GPT 社會化的過程
Prompt
五万字综述！Prompt Tuning：深度解读一种新的微调范式

Circle2
Community
ChatGPT 共学营
talks
B站最强的【Chat GPT保姆级使用教程】
万字科普GPT4为何会颠覆现有工作流
拾象科技 — OpenAI 闭门讨论会
ChatGPT技术分析
详解现象级ChatGPT发展历程、原理、技术架构详解和产业未来
blog
ChatGPT Is a Blurry JPEG of the Web 
万字长文：一文看懂GPT风口，有哪些创业机会？
这一轮AI会带来什么样的范式转移？
理解 AI 驱动的软件 2.0 智能革命 
